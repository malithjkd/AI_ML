{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Physical activity monitoring project - ML model traning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Log in to your W&B account\n",
        "# import wandb\n",
        "\n",
        "import random\n",
        "import math\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Open data chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGgaCfcl1J0J",
        "outputId": "b98249d8-9653-4b00-b358-e937ba41086d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded data from C:\\Users\\malit\\Documents\\GitHub\\AI_ML_data\\PAMAP2_Dataset\\activity_chunks_v1\\subject101_activity_3_chunk_5.csv\n",
            "Data shape: (100, 45)\n",
            "[[549.33      3.      104.      ...  37.8959   -5.75508   1.     ]\n",
            " [549.34      3.      104.      ...  38.8701   -5.50071   1.     ]\n",
            " [549.35      3.      104.      ...  37.5468   -5.8872    1.     ]\n",
            " ...\n",
            " [550.3       3.      105.      ...  38.5598   -5.8717    1.     ]\n",
            " [550.31      3.      105.      ...  37.6758   -5.509     1.     ]\n",
            " [550.32      3.      105.      ...  37.5576   -5.51211   1.     ]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Define the path to your file\n",
        "folder_path = r\"C:\\Users\\malit\\Documents\\GitHub\\AI_ML_data\\PAMAP2_Dataset\\activity_chunks_v1\"\n",
        "\n",
        "file_name_without_ext = \"subject101\"\n",
        "\n",
        "activity_ids = [3, 5, 6, 7]\n",
        "activity_id = 3 # set a default activity id\n",
        "chunk_count = 5 # set a default chunk count\n",
        "\n",
        "file_name = f\"{file_name_without_ext}_activity_{activity_id}_chunk_{chunk_count}.csv\"\n",
        "file_path = os.path.join(folder_path, file_name)\n",
        "\n",
        "# Check if the file exists\n",
        "if not os.path.isfile(file_path):\n",
        "    raise FileNotFoundError(f\"The file {file_path} does not exist.\")\n",
        "\n",
        "# Load the data, specifying the correct delimiter (comma) and no header\n",
        "csv_data = np.loadtxt(file_path, delimiter=',', dtype=float, comments=None, skiprows=0, usecols=None, unpack=False, ndmin=0, encoding='utf-8', max_rows=None)\n",
        "np.set_printoptions(precision=6, suppress=True)\n",
        "\n",
        "print(f\"Loaded data from {file_path}\")\n",
        "print(f\"Data shape: {csv_data.shape}\")  \n",
        "print(csv_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MiniRocket + RidgeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sktime'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RidgeClassifierCV\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msktime\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtransformations\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpanel\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mminirocket\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MiniRocketMultivariate\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sktime'"
          ]
        }
      ],
      "source": [
        "import os, glob, re, random\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "from sklearn.linear_model import RidgeClassifierCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sktime.transformations.panel.minirocket import MiniRocketMultivariate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "DATA_DIR = r\"C:\\\\Users\\\\malit\\\\Documents\\\\GitHub\\\\AI_ML_data\\\\PAMAP2_Dataset\\\\activity_chunks_v1\"\n",
        "TARGET_ACTIVITIES = [3,5,6,7]\n",
        "SAMPLES_PER_CLASS = 50\n",
        "FEATURE_LIMIT = 40\n",
        "SEQ_LEN = 100\n",
        "SEED = 42\n",
        "out_dir = 'models/minirocket_baseline'\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "rng = random.Random(SEED)\n",
        "\n",
        "def parse_activity(fp):\n",
        "    m = re.search(r\"activity_(\\d+)_chunk\", os.path.basename(fp))\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "# 1 Collect & group\n",
        "paths = [p for p in glob.glob(os.path.join(DATA_DIR,'*.csv')) if parse_activity(p) in TARGET_ACTIVITIES]\n",
        "by_act = {a: [] for a in TARGET_ACTIVITIES}\n",
        "for p in paths: by_act[parse_activity(p)].append(p)\n",
        "for a in TARGET_ACTIVITIES: rng.shuffle(by_act[a])\n",
        "\n",
        "# 2 Sample balanced\n",
        "selected = []\n",
        "for a in TARGET_ACTIVITIES: selected.extend(by_act[a][:SAMPLES_PER_CLASS])\n",
        "\n",
        "# 3-5 Load & build tensor list\n",
        "X_list, y_list = [], []\n",
        "for fp in selected:\n",
        "    arr = np.loadtxt(fp, delimiter=',', dtype=float)\n",
        "    feat_idx = [i for i in range(arr.shape[1]) if i not in (0,1)][:FEATURE_LIMIT]\n",
        "    seq = arr[:, feat_idx].T   # (F, T)\n",
        "    if seq.shape != (FEATURE_LIMIT, SEQ_LEN):\n",
        "        continue\n",
        "    X_list.append(seq)\n",
        "    y_list.append(parse_activity(fp))\n",
        "\n",
        "X = np.stack(X_list)  # (N, F, T)\n",
        "y = np.array(y_list)\n",
        "\n",
        "# 6 Split\n",
        "idx = np.arange(len(X)); rng.shuffle(list(idx))\n",
        "tr_end = int(0.7*len(idx)); va_end = int(0.85*len(idx))\n",
        "tr, va, te = idx[:tr_end], idx[tr_end:va_end], idx[va_end:]\n",
        "Xtr, Xva, Xte = X[tr], X[va], X[te]\n",
        "ytr, yva, yte = y[tr], y[va], y[te]\n",
        "\n",
        "# 7-8 MiniRocket fit/transform\n",
        "mr = MiniRocketMultivariate(random_state=SEED)\n",
        "mr.fit(Xtr)\n",
        "Phi_tr = mr.transform(Xtr)\n",
        "Phi_va = mr.transform(Xva)\n",
        "Phi_te = mr.transform(Xte)\n",
        "\n",
        "# 9 RidgeClassifierCV\n",
        "clf = RidgeClassifierCV(alphas=np.logspace(-3,3,7))\n",
        "clf.fit(Phi_tr, ytr)\n",
        "print('Val acc:', clf.score(Phi_va, yva))\n",
        "print('Test acc:', clf.score(Phi_te, yte))\n",
        "print(classification_report(yte, clf.predict(Phi_te)))\n",
        "print(confusion_matrix(yte, clf.predict(Phi_te)))\n",
        "\n",
        "# 10 Save artifacts\n",
        "joblib.dump(mr, os.path.join(out_dir,'transform.pkl'))\n",
        "joblib.dump(clf, os.path.join(out_dir,'ridge.pkl'))\n",
        "with open(os.path.join(out_dir,'config.json'),'w') as f:\n",
        "    json.dump({'activities': TARGET_ACTIVITIES, 'feature_limit': FEATURE_LIMIT, 'seq_len': SEQ_LEN, 'seed': SEED}, f, indent=2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMLzs8uQIGvYe2GkAYy1+wD",
      "include_colab_link": true,
      "mount_file_id": "1d6BYhms4xYRR7pAIGG8fiLIWccB15nlm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
